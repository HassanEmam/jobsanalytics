{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job Text Analytics\n",
    "\n",
    "The main aim of this project is to scrape jobs from websites like indeed related to project contols personnel and analyse key features needed in the market. Using text analytics top competencies can be extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "\n",
    "These functions are designed to extract and clean text from webpages\n",
    "Extracted data are job title, url, advertising company, location, summary, and full job description\n",
    "These are achieved by identifying HTML tags along with attributes such as classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(item):\n",
    "    if item:\n",
    "        return item.text.strip()\n",
    "    else:\n",
    "        return ''\n",
    "    \n",
    "def get_title_from_result(result):\n",
    "    return result.find('a',{'data-tn-element': 'jobTitle'}).text.strip()\n",
    "\n",
    "def get_full_jd(result):\n",
    "    if result is None: \n",
    "        return None\n",
    "    return extract_text(result.find('div',{'class': 'jobsearch-JobComponent-description'}))\n",
    "\n",
    "def get_url(result):\n",
    "    a = result.find('a',{'data-tn-element': 'jobTitle'})\n",
    "    return(a['href'])\n",
    "    \n",
    "def get_company_from_result(result):\n",
    "    return extract_text(result.find('span',{'class': 'company'}))\n",
    "\n",
    "def get_location_from_result(result):\n",
    "    return extract_text(result.find('span',{'class': 'location'}))\n",
    "\n",
    "def get_summary_from_result(result):\n",
    "    return extract_text(result.find('span',{'class': 'summary'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping\n",
    "\n",
    "This section performs the web scraping from indeed. There are two main parameters used during the scraping:\n",
    "1- Salary range - this varies between countries\n",
    "2- page number (start variable) \n",
    "\n",
    "The code loops through both variables creating links with search parameters and extracts job attributes apart from detailed job descritption. Each individual job is stored in a dictionary and all jobs are added into a list.\n",
    "\n",
    "The data are dumped into a json file for presistence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.indeed.com/jobs?q=%22project+control%22+${}%2C000&l=USA&radius=100&jt=fulltime&limit=500\"\n",
    "UKurl =\"https://www.bayt.com/en/international/jobs/q/project-controls/?page={}\"\n",
    "max_result_per_city=6000\n",
    "\n",
    "rows=[]\n",
    "# for salary in set(['55-70','70-85','85-100','100-115']):\n",
    "for salary in set(['35-40','40-45','45-50','50-55', '55-60']):\n",
    "    for start in range(10):\n",
    "        r=requests.get(UKurl.format(salary, start))\n",
    "        soup=BeautifulSoup(r.content,\"lxml\")\n",
    "        results=soup.findAll('div',{'class':  'result'})\n",
    "        for result in results:\n",
    "            if result:\n",
    "                row={}\n",
    "                row['title']=get_title_from_result(result)\n",
    "                row['company']=get_company_from_result(result)\n",
    "                row['city']=get_location_from_result(result)\n",
    "                row['summary']=get_summary_from_result(result)\n",
    "                row['bin']=salary\n",
    "                row['url'] = get_url(result)\n",
    "                \n",
    "                rows.append(row)\n",
    "\n",
    "with open('UKdata.json', 'w') as outfile:\n",
    "    json.dump(rows, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Show Sample of data gathered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Detailed Job Description\n",
    "\n",
    "Using URLs collected earlier and stored in the json file, detailed job description are collected and appended to the existing data and stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('UKdata.json') as f:\n",
    "    data = json.load(f)\n",
    "urls = []    \n",
    "for j in data:\n",
    "    url =\"https://www.indeed.com/viewjob?\"\n",
    "    ukurl =\"https://www.indeed.co.uk/viewjob?\"\n",
    "    ukurl += j['url'].split('?')[1]\n",
    "    urls.append(ukurl)\n",
    "urls[1]\n",
    "\n",
    "count = 0 \n",
    "for url in urls:\n",
    "    r=requests.get(url)\n",
    "    soup=BeautifulSoup(r.content,\"lxml\")\n",
    "    result = soup.find('div',{'class':  'jobsearch-ViewJobLayout-jobDisplay'})\n",
    "    rows[count].update({'JD' : get_full_jd(result)})\n",
    "    count +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store data into a json file\n",
    "\n",
    "The data are stored into a json file and a sample of collected data is shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print (sys.stdout.encoding)\n",
    "with open('ukdata.json', 'w') as outfile:\n",
    "    json.dump(rows, outfile)\n",
    "    \n",
    "rows[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
